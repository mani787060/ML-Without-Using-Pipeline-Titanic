## Machine Learning Without Using Pipeline — Titanic Dataset

-> This project demonstrates how to perform **data preprocessing, feature encoding, and model training manually** using the **Titanic Survival dataset**, without relying on scikit-learn       pipelines.

-> By building each step separately, we get a clear understanding of the inner workflow that pipelines later automate.


# Topics Covered:-
-> Data cleaning and preprocessing  
-> Handling missing values  
-> Encoding categorical features  
-> Splitting data into train and test sets  
-> Training and testing a model (without pipeline)


# Libraries Used:-
-> pandas  
-> numpy  
-> scikit-learn  


# Dataset:-
-> The project uses the "Titanic Survival dataset", which contains passenger details such as age, gender, class, and survival status.


# Key Takeaway:-
Working without pipelines helps you:
-> Understand the "order and importance" of preprocessing steps  
-> See how transformations are applied separately  
-> Appreciate how pipelines "simplify and automate" the same process


=> Note:- This project complements the “Using Pipeline” notebook by showing how ML workflows are built manually from scratch.
